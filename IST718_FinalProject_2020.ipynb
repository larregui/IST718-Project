{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/larregui/IST718-Project/blob/main/IST718_FinalProject_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKnAD5Neaf3Q"
   },
   "source": [
    "# Title: Out of This World\n",
    "# Author: Laura & Tiffannie\n",
    "# Purpose: Final Project for IST 718 Big Data Analytics\n",
    "# Professor: Jon Fox\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQZmcssv6LPN"
   },
   "source": [
    "## Resources  \n",
    "https://www.kaggle.com/rkd286/ufo-sightings-eda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkE94Z29a70Q"
   },
   "source": [
    "### Import Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UiwvqpJJWyJu",
    "outputId": "dd7bfd20-aa6a-49a5-a13a-1c8d607b3e2e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd #data frame operations\n",
    "import numpy as np #arrays and math functions\n",
    "from scipy.stats import uniform #for training and test splits\n",
    "import statsmodels.api as sm  # statistical models (including regression)\n",
    "import statsmodels.formula.api as smf  # R-like model specification\n",
    "import matplotlib.pyplot as plt #2D plotting\n",
    "import seaborn as sns #seaborn for plotting\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "from plotly.offline import iplot, init_notebook_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67Ve9i5sbLK0"
   },
   "source": [
    "### Import Dataset and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wGn3xFe0W2ze",
    "outputId": "09568174-8682-4a1d-bd14-c57efd5fbcf6"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /content/ufo.csv does not exist: '/content/ufo.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7de6ecccc68e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# read in UFO data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mufo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/content/ufo.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# shape and data types of the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"What are the dimensions of the dataset?\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mufo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"What are the datatypes for each variable?\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mufo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File /content/ufo.csv does not exist: '/content/ufo.csv'"
     ]
    }
   ],
   "source": [
    "# read in UFO data\n",
    "ufo = pd.read_csv(\"/content/ufo.csv\")\n",
    "# shape and data types of the data\n",
    "print(\"What are the dimensions of the dataset?\\n\",ufo.shape)\n",
    "print(\"What are the datatypes for each variable?\\n\",ufo.dtypes)\n",
    "# compute descriptive statistics \n",
    "print(\"Descriptive Statistics\\n\",ufo.describe())\n",
    "# % of missing.\n",
    "for col in ufo.columns:\n",
    "    pct_missing = np.mean(ufo[col].isnull())\n",
    "    print(\"Are there any null values?\\n\",'{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9bfAuBXeyhYX",
    "outputId": "c6dc196d-2b01-4333-f9b0-7481ed009294"
   },
   "outputs": [],
   "source": [
    "# read in Movie data\n",
    "mov = pd.read_csv(\"alien_movies.csv\")\n",
    "# shape and data types of the data\n",
    "print(\"What are the dimensions of the dataset?\\n\",mov.shape)\n",
    "print(\"What are the datatypes for each variable?\\n\",mov.dtypes)\n",
    "mov = mov.drop([ 'Unnamed: 2', 'Unnamed: 3'], axis=1)\n",
    "# % of missing.\n",
    "for col in mov.columns:\n",
    "    pct_missing = np.mean(mov[col].isnull())\n",
    "    print(\"Are there any null values?\\n\",'{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jZR2daeXy2WU",
    "outputId": "29af552a-ba19-4596-faee-a3d9d3219b15"
   },
   "outputs": [],
   "source": [
    "# read in Movie data\n",
    "air = pd.read_csv(\"us-airports.csv\")\n",
    "# shape and data types of the data\n",
    "print(\"What are the dimensions of the dataset?\\n\",air.shape)\n",
    "print(\"What are the datatypes for each variable?\\n\",air.dtypes)\n",
    "air = air.drop([ 'last_updated', 'wikipedia_link', 'home_link','gps_code','continent', \n",
    "                'keywords','iata_code', 'local_code', 'iso_country','iso_region', 'country_name', 'score'], axis=1)\n",
    "# % of missing.\n",
    "for col in air.columns:\n",
    "    pct_missing = np.mean(air[col].isnull())\n",
    "    print(\"Are there any null values?\\n\",'{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0LvXI2NXkdG"
   },
   "source": [
    "The dataset has 11 variables and 80,332 records. \n",
    "The following columns have missing values:\n",
    "\n",
    "\n",
    "*   state - 7%\n",
    "*   Country - 12%\n",
    "*   Shape - 2%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7R7OUzwnYLLV"
   },
   "outputs": [],
   "source": [
    "#change attributes data type as needed\n",
    "ufo['datetime'] = pd.to_datetime(ufo['datetime'], errors='coerce')\n",
    "ufo.insert(1, 'year', ufo['datetime'].dt.year)\n",
    "ufo['year'] = ufo['year'].fillna(0).astype(int)\n",
    "\n",
    "#print(ufo.country.unique())\n",
    "#print(len(ufo.country),\"Contries\")\n",
    "# The datase includes records from US, GB, CA, AU, and DE.\n",
    "# Should we study one country?\n",
    "nufo = ufo[ufo.country == 'us']\n",
    "\n",
    "us_states = np.asarray(['AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA',\n",
    "                        'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME',\n",
    "                        'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM',\n",
    "                        'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX',\n",
    "                        'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8PINgTvZt6W"
   },
   "source": [
    "### Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518
    },
    "id": "3-uEQrFBZyV9",
    "outputId": "755d67fd-1e69-445e-e626-bf820894d0d4"
   },
   "outputs": [],
   "source": [
    "# Barplot - UFO Shapes\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.set_style(\"darkgrid\")\n",
    "ax = sns.barplot(x =nufo['shape'].value_counts().head().index, y = nufo['shape'].value_counts().head().values, color = 'green')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "ax.set_xlabel('Shape').set_size(20)\n",
    "ax.set_ylabel('Count').set_size(20)\n",
    "ax.set_title('TOP 5 SHAPES').set_size(20)\n",
    "plt.tight_layout()\n",
    "for p in ax.patches:\n",
    "        p.set_width(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CC_76fuj5Qi_"
   },
   "outputs": [],
   "source": [
    "hours_high = nufo['datetime'].dt.hour.value_counts()\n",
    "years_high = nufo['datetime'].dt.year.value_counts().head()\n",
    "month_high = nufo['datetime'].dt.month.value_counts()\n",
    "def top_years(year):\n",
    "    if year in years_high.index:\n",
    "        return year\n",
    "hour_vs_year = nufo.pivot_table(columns=nufo['datetime'].dt.hour,index=nufo['datetime'].dt.year.apply(top_years),aggfunc='count',values='city')\n",
    "hour_vs_year.columns = hour_vs_year.columns.astype(int)\n",
    "hour_vs_year.columns = hour_vs_year.columns.astype(str) + \":00\"\n",
    "hour_vs_year.index = hour_vs_year.index.astype(int)\n",
    "\n",
    "month_vs_year = nufo.pivot_table(columns=nufo['datetime'].dt.month,index=nufo['datetime'].dt.year.apply(top_years),aggfunc='count',values='city')\n",
    "month_vs_year.columns = month_vs_year.columns.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "xSJ6632F5ECz",
    "outputId": "a034f0da-3eeb-4d8c-bb90-89825127bf33"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "ax = sns.heatmap(hour_vs_year)\n",
    "ax.set_xlabel('Hours').set_size(20)\n",
    "ax.set_ylabel('Year').set_size(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506
    },
    "id": "t653cXet6m7u",
    "outputId": "0d285190-ddef-4d7d-8cad-3a147bdd5cef"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "ax = sns.heatmap(month_vs_year)\n",
    "ax.set_xlabel('Month').set_size(20)\n",
    "ax.set_ylabel('Year').set_size(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "A81zyGY477iN",
    "outputId": "eb8dc78f-18e2-4663-b960-953c233f1306"
   },
   "outputs": [],
   "source": [
    "# UFO sightings per state\n",
    "ufo_perstate = np.asarray(nufo.groupby('state').state.count())\n",
    "\n",
    "ufo_scale = [[0, 'rgb(229, 249, 239)'], [1, 'rgb(0, 163, 81)']]\n",
    "\n",
    "data = [dict(\n",
    "        type = 'choropleth',\n",
    "        autocolorscale = False,\n",
    "        colorscale = ufo_scale,\n",
    "        showscale = False,\n",
    "        locations = us_states,\n",
    "        locationmode = 'USA-states',\n",
    "        z = ufo_perstate,\n",
    "        marker = dict(\n",
    "            line = dict(\n",
    "                color = 'rgb(255, 255, 255)',\n",
    "                width = 2)\n",
    "            )\n",
    "        )]\n",
    "\n",
    "layout = dict(\n",
    "         title = 'UFO Reports by State in United States',\n",
    "         geo = dict(\n",
    "             scope = 'usa',\n",
    "             projection = dict(type = 'albers usa'),\n",
    "             countrycolor = 'rgb(255, 255, 255)',\n",
    "             showlakes = True,\n",
    "             lakecolor = 'rgb(255, 255, 255)')\n",
    "        )\n",
    "\n",
    "figure = dict(data = data, layout = layout)\n",
    "iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "vKRUzqOW1Lqb",
    "outputId": "0c114d97-f863-4b8a-b3fe-8d45067a130f"
   },
   "outputs": [],
   "source": [
    "#wordcloud\n",
    "\n",
    "cols2drop=['datetime', 'city', 'state', 'country','shape','duration (seconds)', 'duration (hours/min)', 'date posted',\n",
    "       'latitude', 'longitude ']\n",
    "w_nufo=nufo.drop(columns=cols2drop)\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "comment_strng = str(w_nufo.comments)\n",
    "wordcloud = WordCloud(width=1000, height=1000, max_font_size=20, min_font_size=10, colormap=\"Blues\").generate(comment_strng)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.margins(x=0, y=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-buoLfGkZVXy"
   },
   "source": [
    "### Build a training and testing dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXQANipHZVEC",
    "outputId": "f55a4f39-858d-49e0-e368-49b6f9a6819e"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "nufo['runiform'] = uniform.rvs(loc = 0, scale = 1, size = len(nufo))\n",
    "train = nufo[nufo['runiform'] >= 0.33]\n",
    "test = nufo[nufo['runiform'] < 0.33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wfwxtt5jbQd-"
   },
   "source": [
    "### Initial data analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mZzAyZucTNt"
   },
   "source": [
    "### Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tz0Ks_8z48vO"
   },
   "source": [
    "### Random Forest  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbhP9kqnEy2s"
   },
   "source": [
    "#### Association Rule Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X77LLWCbI7JU"
   },
   "outputs": [],
   "source": [
    "nufo.columns\n",
    "cols2drop=['duration (seconds)', 'duration (hours/min)', 'comments', 'date posted',\n",
    "       'latitude', 'longitude ', 'runiform']\n",
    "arm_nufo=nufo.drop(columns=cols2drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUxHvd75E2vX"
   },
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules \n",
    "#nufo.columns\n",
    "cols2drop=['duration (seconds)', 'duration (hours/min)', 'comments', 'date posted',\n",
    "       'latitude', 'longitude ', 'runiform']\n",
    "arm_nufo=nufo.drop(columns=cols2drop)\n",
    "# Sightings done in California \n",
    "basket_CA = (arm_nufo[arm_nufo['state'] ==\"CA\"]) \n",
    "# Defining the hot encoding function to make the data suitable  \n",
    "# for the concerned libraries \n",
    "def hot_encode(x): \n",
    "    if(x<= 0): \n",
    "        return 0\n",
    "    if(x>= 1): \n",
    "        return 1\n",
    "  \n",
    "# Encoding the datasets \n",
    "basket_encoded = basket_CA.applymap(hot_encode) \n",
    "basket_CA = basket_encoded \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "b4-hACzuIwME",
    "outputId": "3754578f-4d93-41eb-e0d2-766e18e9138a"
   },
   "outputs": [],
   "source": [
    "# Building the model \n",
    "frq_items = apriori(basket_CA, min_support = 0.05, use_colnames = True) \n",
    "  \n",
    "# Collecting the inferred rules in a dataframe \n",
    "rules = association_rules(frq_items, metric =\"lift\", min_threshold = 1) \n",
    "rules = rules.sort_values(['confidence', 'lift'], ascending =[False, False]) \n",
    "print(rules.head()) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNHh9Ewg0Cr0sOy8FKPflSC",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "IST718_FinalProject_2020.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
